---
layout: post
title: "Episode 23"
date: 2024-08-09
enclosure:
  url: https://ikowave.github.io/podcast/episodes/episode23.mp3
  type: audio/mpeg
  length: 1140000
itunes:
  duration: 00:14:00
  summary: Ikowave Podcast - Episode 23: OpenAI Developments and Advancements in AI
---
Ikowave Podcast - Episode 23: OpenAI Developments and Advancements in AI


Welcome back to the Ikowave Podcast! We were silent these past 2 months so this episode has a lot of updates but all related to OpenAI. This is Episode 23, and I'm Adam, your host. Today, we're breaking down the latest news from OpenAI's recent newsletter and also the recent paper published by OpenAI named GPT-4o System Card. There's a lot to cover, from upcoming events to cutting-edge features and cost-saving opportunities for developers and business owners. So, let's jump right in.


OpenAI DevDay: A Global Experience


First up, OpenAI is taking its DevDay on the road this year! If you're a developer working with AI or just interested in the latest advancements, this is a fantastic opportunity to get hands-on experience with OpenAI's tools and technologies. DevDay will be hosted in three major cities: San Francisco, London, and Singapore.


At these events, you'll be able to participate in workshops, see demos, and hear from developers across the globe who are building with OpenAI. It's not just about learning—it's also about networking and possibly getting your work featured onstage. If you're interested, make sure to apply to attend in person. It’s a rare chance to connect with the people who are shaping the future of AI.


Structured Outputs: Bringing Precision to AI Models


Next, let’s talk about one of the most exciting new features from OpenAI—Structured Outputs. This feature is designed to ensure that the outputs generated by AI models conform exactly to predefined JSON Schemas. This is a game-changer for developers who need precise and predictable outputs from their models, particularly when integrating AI into applications that require structured data.


Structured Outputs can be accessed in two ways: through function calling or by using the response_format parameter with a new json_schema option. If you're building applications that rely on clean, structured data, this is a feature you’ll definitely want to explore. The OpenAI documentation has all the details to get you started.


Cost Savings with the New GPT-4o Snapshot


Now, onto something that’s sure to catch everyone's attention—cost savings. OpenAI has just released a new snapshot of GPT-4o, labeled as gpt-4o-2024-08-06. This update is not only more efficient but also significantly cheaper. Input tokens are 50% cheaper, and output tokens are 33% cheaper compared to the original GPT-4o. And, yes, it also supports the new Structured Outputs feature.


For developers working on large-scale projects, this could translate to substantial savings. It’s a great time to re-evaluate your AI models and see how this new version can optimize both performance and cost.


Introducing GPT-4o Mini: Small, Fast, and Cost-Effective


In addition to the new GPT-4o snapshot, OpenAI has introduced GPT-4o Mini. This model is not only smaller but also cheaper—60% cheaper than GPT-3.5 Turbo—while still offering advanced capabilities. It’s designed for those who need speed and efficiency without compromising on intelligence.


What’s more, OpenAI is offering free fine-tuning for GPT-4o Mini through September 23. If you’re a paid API user on tiers 1-5, you can fine-tune up to 2 million training tokens per day at no extra cost. This is a golden opportunity to customize your models to better suit your needs without breaking the bank.


Recent Feature Updates: Text-to-Speech, Function Calling, and More


Since our last episode, OpenAI has rolled out several new features. Here are a few highlights:


Text-to-Speech in the Playground: You can now generate audio directly in the Playground using one of six preset voices. This makes building with the text-to-speech API easier than ever.


Function Calling in the Playground: OpenAI has also made it easier to test and define functions with the new function calling feature. This allows models to output JSON objects containing arguments to call your functions, streamlining the development process.


Admin and Audit Logs APIs: For those managing larger teams or organizations, the new Admin API lets you programmatically manage invites, users, projects, and service accounts. Meanwhile, the Audit Logs API helps keep track of logins and changes within your organization, ensuring better security and compliance.


.NET SDK: Finally, together with Microsoft, OpenAI has released a .NET SDK, currently in beta. This makes it easier to integrate OpenAI’s models into your .NET applications. You can find the SDK on GitHub and check out the accompanying documentation to get started.


Now onto something that OpenAI just released yesterday, August 8th 2024. The GPT-4o System Card paper. We're going to dive deeper into the capabilities and safety measures surrounding OpenAI's latest release: GPT-4o, as detailed in their newly published GPT-4o System Card.


Introducing GPT-4o: The Omni Model


Let's understand what the O stands for in the name GPT-4o. It is not just another language model—it's an "omni model," capable of processing and generating text, audio, image, and video outputs. This means GPT-4o is trained to understand and produce content across multiple modalities, making it a versatile tool for a wide range of applications. Whether you're dealing with audio inputs or generating text, GPT-4o handles it all through a unified neural network. This integration leads to more cohesive outputs and faster processing times, with audio responses clocking in at an impressive 232 to 320 milliseconds—comparable to human conversation speeds.


Advancements and Cost Efficiency


What makes GPT-4o stand out is its significant improvement in handling non-English languages and multimodal data compared to previous models. It's also faster and more cost-effective—50% cheaper for input tokens and 33% cheaper for output tokens compared to its predecessor, GPT-4 Turbo.


For developers, this means more efficient and affordable access to advanced AI capabilities, especially for applications requiring multi-language support or intricate data processing across text, images, and audio.


Safety and Preparedness


As powerful as GPT-4o is, OpenAI has put substantial effort into ensuring its safe deployment. The GPT-4o System Card details various safety evaluations, including the Preparedness Framework assessments. These evaluations focus on the model's ability to handle potential risks like bias, misinformation, and unauthorized use of its advanced voice capabilities.


For instance, the model has been trained to refuse tasks that could involve identifying a speaker based on their voice to protect privacy. It also includes mitigations against generating copyrighted content or making ungrounded inferences about sensitive traits, like intelligence or socioeconomic status, based on audio inputs.


Red Teaming and External Assessments


To ensure robust safety measures, OpenAI collaborated with over 100 external experts from around the world, who conducted rigorous red teaming on the model. These experts tested the model's responses across various stages of its development, helping to identify and mitigate potential risks, particularly those associated with the new speech-to-speech capabilities.


For example, GPT-4o was tested for its ability to generate unauthorized voices, a potential risk that could be exploited for fraud or misinformation. OpenAI mitigated this by limiting the model to pre-approved voices and using classifiers to detect and block any deviations from these voices.


Risks and Limitations


Despite the extensive safety measures, the GPT-4o System Card also acknowledges the model's limitations and areas where further work is needed. These include challenges in handling low-quality audio inputs, background noise, and the risk of generating persuasive but inaccurate information through speech.


Additionally, OpenAI is actively working on improving the model's performance across different accents and languages to ensure fair and consistent service for all users, regardless of their voice characteristics.


Societal Impacts and Future Directions


The GPT-4o System Card doesn't shy away from discussing the broader societal impacts of deploying such a powerful model. From the potential benefits in healthcare and scientific research to the risks of anthropomorphization and emotional reliance on AI, OpenAI is committed to monitoring and addressing these issues as the technology evolves.


The card also highlights the model's improved performance in underrepresented languages, narrowing the gap between these languages and English. This progress is crucial for making AI more inclusive and accessible worldwide.


Paper Conclusion and Next Steps


As GPT-4o rolls out, OpenAI will continue to refine its safety protocols, explore the model's capabilities, and assess its societal impacts. The company is also encouraging further research and collaboration to address the remaining challenges and ensure that AI development proceeds in a responsible and ethical manner.


Developer Resources


Now that we concluded the paper review, let's check out some Developer Resources


OpenAI has updated its documentation page, regularly adding new guides, sample apps, and cookbooks. These resources are invaluable for both beginners and seasoned developers looking to expand their knowledge and build more sophisticated AI applications. You can find these resources and new libraries in their documentation.


That wraps up today’s episode of the Ikowave Podcast. Whether you’re looking to attend DevDay, optimize your AI models, or just stay updated on the latest tools, there’s a lot happening in the world of OpenAI right now. Thanks for tuning in, and we’ll catch you next time with more insights into the rapidly evolving AI landscape. Stay curious and keep innovating!

Source; Openai.com
