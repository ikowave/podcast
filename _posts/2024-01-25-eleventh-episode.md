---
layout: post
title: "Episode 11"
date: 2024-01-25
enclosure:
  url: https://ikowave.github.io/podcast/episodes/episode11.mp3
  type: audio/mpeg
  length: 7464000
itunes:
  duration: 00:15:02
  summary: Discuss the Memo by Dr. Alan D. Thompson and Singularity Book
---
*** Welcome to Episode 11 of IKOwave, aired on 25th January, 2024. ***

Today we will be discussing an article, "The Memo," published on the 24th of January, 2024, authored by Dr. Alan D. Thompson. This timely piece focuses on advancements in AI, exploring an array of updates from the use of OpenAI to Zhipu GLM-4, along with a detailed discussion on political robocalls featuring artificial voices.

We open with a quote from Ilya Sutskever, OpenAI (15/Mar/2023):

"Say you read a detective novel… complicated plot, a storyline, different characters, lots of events, mysteries, clues, it’s unclear. Then, let’s say that at the last page of the book, the detective has gathered all the clues, gathered all the people and saying: ‘Okay, I’m going to reveal the identity of whoever committed the crime and that person’s name is…’ Predict that word. Now, there are many different words. But predicting those words better and better, the understanding of the text keeps on increasing. GPT-4 predicts the next word better."

Diving into that quote and thought - how does chatGPT works? To delve deeper into how ChatGPT makes predictions, think of it as a highly advanced pattern recognition system. It's based on a type of artificial intelligence called a neural network, which is inspired by the human brain's structure. This network has been trained on a massive dataset of text, allowing it to learn language patterns, idioms, facts, and even styles of writing.

When you ask ChatGPT a question or give it a prompt, it doesn't just search for a pre-written answer. Instead, it generates a response in real-time. It does this by predicting the most likely next word or phrase, based on the context of your question and everything it has learned during its training. It's like a highly skilled writer quickly composing a reply, considering not only the meaning of each word but also how words work together to convey a particular thought or answer.

Each word it chooses influences the next, allowing it to construct coherent and contextually relevant sentences. This process happens rapidly, almost instantaneously, enabling ChatGPT to maintain a smooth and natural conversation flow. Despite its complexity, the end result is a user-friendly interface where the technology fades into the background, leaving you with the feeling of having a natural, human-like interaction.

Now generative AI for images, like the technology behind DALL-E, works quite differently from text-based models like ChatGPT. Imagine an artist who can create any image you describe, no matter how fantastical. That's what image-generating AI does. It uses a method called deep learning, where a neural network is trained on a vast dataset of images and their descriptions. This training enables the AI to understand and correlate visual elements with descriptive words.

When you provide a description to this AI, it doesn't just retrieve a matching image; it generates a new image from scratch. It does so by predicting what elements should be in the image, where they should be located, and how they should look, based on the patterns it learned during training. The AI considers shapes, colors, textures, and the relationships between different objects described in your prompt.

This process is akin to an extremely rapid and complex decision-making task, where the AI decides on every pixel of the image, ensuring that each contributes to a coherent whole that matches your description. The result is often stunningly creative and detailed, showcasing the AI's ability to blend learned artistic concepts with the unique requirements of your request. In essence, generative AI for images is like a fusion of a highly skilled artist and a powerful computer, capable of bringing any vision to visual reality.

Back to the article, Thompson begins by summarizing a key point made by Ilya Sutskever, the co-founder of OpenAI, on the evolution of AI's text comprehension and prediction capabilities. He uses the metaphor of a detective novel to explain the sophisticated functioning of OpenAI's GPT-4 model.

The article also delves into DeepMind AlphaGeometry, an AI system capable of solving complex geometry problems at an Olympiad level. This system has made significant strides, even hinting at a future where an AI system could potentially win an International Mathematical Olympiad Gold Medal.

Thompson then highlights Meta's announcement about the training of its next-gen model, Llama 3, and its purchase of a large number of H100s. Moreover, the article also highlights the progress of Chinese AI labs with the new GLM-4 model by Zhipu AI, and the misleading political robocalls with artificially generated voices that were spread during the 2024 US elections.

Lastly, the article discusses OpenAI's partnership with Arizona State University, the upcoming release of Ray Kurzweil's book "The Singularity is Nearer," and Amazon's new AI-version of Alexa.

Continuing the podcast, we have an interview with Ray Kurzweil, one of the world’s leading inventors, thinkers, and futurists with a decades-long track record of accurate predictions.

In the interview, Kurzweil discusses a range of topics including his views on the advancements of AI, Kurzweil's forecasts on AI's potential to surpass human capabilities, and his outlook on the future. He confidently asserts his belief in the possibility of AI passing the Turing Test by 2029 and shares his optimism about AI aiding us to become smarter by integrating AI with our minds in the 2030s.

Kurzweil takes us on a fascinating dive into the future, imagining a time when we can connect our brains to the cloud, dramatically amplifying our ability to think and process information. He also stresses the importance of collecting data to simulate biology and the potential to find solutions to every medical problem using simulated biology.

Additionally, he highlights the potential of AI in reshaping fields like education, reflecting on the current reality where large language models are transforming academic research.

When asked about the future of democracy and technology, Kurzweil maintains an optimistic outlook, emphasizing that despite the problems, the spread of democracy around the world has increased with the advancement of technology.

Towards the end of the interview, he discusses the intriguing concept of 'computronium', the theoretical 'ultimate' form of computational matter, hinting at a future when humanity may need to look beyond Earth to continue our computational expansion.

So this was a brief summary of the insights from the conversation with Ray Kurzweil. Be sure to tune in to our next episode for more enlightening discussions on the intersection of technology, science, and society!