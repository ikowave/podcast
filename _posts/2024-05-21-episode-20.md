---
layout: post
title: "Episode 20"
date: 2024-04-09
enclosure:
  url: https://ikowave.github.io/podcast/episodes/episode20.mp3
  type: audio/mpeg
  length: 5830000
itunes:
  duration: 00:06:22
  summary: News from AI
---
Episode 20: Ikowave Podcast Summary 


 

Welcome to Episode 20 of the Ikowave Podcast! Today, we've got an exciting lineup of the latest and greatest in AI developments. Let’s dive right in! 


 

First up, DrEureka AI! This cutting-edge AI system, developed by NVIDIA, UPenn, and UT Austin, uses GPT-4 to revolutionize robotics. Imagine a robot dog balancing on a yoga ball without any fine-tuning—DrEureka makes it possible by automating the training and deployment of these skills. This is a significant leap in AI's capability to bridge the simulation-reality gap in robotics. 


 

Next, let’s talk about Neuralink. Noland Arbaugh, the first participant in the PRIME study, has been using the Link brain-computer interface for 100 days. This incredible technology has given him newfound independence, allowing him to control his laptop and play games from various positions, even while lying down. It's a life-changer, reconnecting him with friends and family and enhancing his gaming experience. 


 

Now, onto DeepSeek-V2. DeepSeek-AI has unveiled a new 236 billion parameter model, trained on an astounding 8.1 trillion token dataset. While it’s showing promising results, there’s still a slight gap in English capabilities compared to smaller models. But the sheer scale and ambition of this project are worth noting. 


 

And meet Victoria Shi, the digital representative of Ukraine’s Ministry of Foreign Affairs. This AI persona provides timely updates on consular affairs, representing a significant step forward in the use of digital avatars for official communications. However, the reliance on QR codes for authenticity has raised some concerns about security. 


 

Let’s shift gears to Google I/O 2024. Google announced a host of new AI innovations: 


 

Gemini 1.5 Flash is a fast, efficient model perfect for low-latency tasks. 


PaliGemma focuses on visual Q&A and image captioning. 


Project Astra introduces future AI assistants that understand context and respond quickly. 


Veo is a new video generation model capable of producing high-quality 1080p videos. 


Imagen 3 enhances image generation with improved natural language understanding and text rendering. 


Music AI Sandbox offers tools for creating new instrumental sections and transferring styles between tracks. 


Gemini Advanced allows for the creation of personalized AI models and detailed planning features. 


OpenAI has also been busy. They introduced GPT-4o, a multimodal model that integrates text, audio, and vision, delivering high performance at a lower cost and faster speed than GPT-4 Turbo. Plus, they’ve expanded access to new features for free-tier ChatGPT users, including file uploads and real-time interaction with tables and charts. 


 

Other notable developments include: 


 

ElevenLabs Dubbing API, which preserves original speaker characteristics in translations. 


Tencent’s Hunyuan-DiT, a text-to-image model excelling in both English and Chinese. 


Hugging Face’s ZeroGPU, offering free GPU resources for indie and academic projects. 


Apple’s Eye Tracking feature for iPads and iPhones, enhancing accessibility. 


Anthropic’s Prompt Generation Tool, which helps create more effective AI prompts. 


Google’s Gemini API Developer Competition, with $1 million in cash prizes up for grabs. 


Lastly, OpenAI has pulled the conversational chat voice named "Sky" after Scarlett Johansson sent OpenAI a few letters and threatened legal action over the fact that the voices are very similar. OpenAI disabled the voice while they address the concerns internally. Let's hear her statement; it has some interesting messages. Here's her statement: 


 

"Last September, I received an offer from Sam Altman, who wanted to hire me to voice the current ChatGPT 4.0 system. He told me that he felt that by my voicing the system, I could bridge the gap between tech companies and creatives and help consumers to feel comfortable with the seismic shift concerning humans and AI. He said he felt that my voice would be comforting to people. 


 

After much consideration and for personal reasons, I declined the offer. Nine months later, my friends, family, and the general public all noted how much the newest system named "Sky" sounded like me. 


 

When I heard the released demo, I was shocked, angered, and in disbelief that Mr. Altman would pursue a voice that sounded so eerily similar to mine that my closest friends and news outlets could not tell the difference. Mr. Altman even insinuated that the similarity was intentional, tweeting a single word "her" - a reference to the film in which I voiced a chat system, Samantha, who forms an intimate relationship with a human. 


 

Two days before the ChatGPT 4.0 demo was released, Mr. Altman contacted my agent, asking me to reconsider. Before we could connect, the system was out there. 


 

As a result of their actions, I was forced to hire legal counsel, who wrote two letters to Mr. Altman and OpenAI, setting out what they had done and asking them to detail the exact process by which they created the "Sky" voice. Consequently, OpenAI reluctantly agreed to take down the "Sky" voice. 


 

In a time when we are all grappling with deepfakes and the protection of our own likeness, our own work, our own identities, I believe these are questions that deserve absolute clarity. I look forward to resolution in the form of transparency and the passage of appropriate legislation to help ensure that individual rights are protected." 


 

That’s it for this episode of the Ikowave Podcast! Stay tuned for more insights and updates on the fascinating world of AI. Thanks for listening, and we’ll catch you next time!


