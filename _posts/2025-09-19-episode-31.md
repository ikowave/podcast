---
layout: post
title: "Episode 31"
date: 2025-09-19
enclosure:
  url: https://ikowave.github.io/podcast/episodes/episode31.mp3
  type: audio/mpeg
  length: 2000000
itunes:
  duration: 00:28:41
  summary: How People Use ChatGPT  Insights from New Research
  image: https://ikowave.github.io/podcast/assets/ikowave.png
---
Ikowave EP31 - How People Use ChatGPT  Insights from New Research

 Welcome to the Deep Dive. We're the show that unpacks the latest research, the big studies, and turns all that dense information into something you can actually use.

 Yeah, cutting through the noise.

 Exactly. And today, oh, boy. We're diving into something huge. A technology that's basically changed everything in just a couple of years.

 You mean ChatGPT?

 You got it.

 We've got our hands on a massive new study. Hot off the presses. NBER working paper number three four two five five. It just came out September twenty twenty five.

 Right. The title is how People Use ChatGPT. And this isn't just guesswork or, you know, asking a few people.

 No way. This is the real deal. They analyzed millions, literally millions of actual user interactions. So we're finally getting a proper look at how this AI is being woven into, well, everyday life.

 And maybe just a quick setup for anyone who needs it. ChatGPT. It's that AI chatbot everyone's talking about, right?

 Built on what they call a large language model, an LLM.

 Basically, it's been trained on just unbelievable amounts of text data. The internet books, everything. And it's incredibly good at predicting the next word. So it writes stuff that sounds, well, human.

 Spookily human sometimes. And when it launched back near the end of twenty twenty two, we knew it was big. But the speed. The speed is what gets me. It's nuts. This paper nails it down. Get this by July twenty twenty five. Just a few months ago, ChatGPT had over seven hundred million weekly users.

 Let that sink in. Yeah, seven hundred million every single week.

 That's roughly what, ten percent of all adults on the planet?

 Pretty much ten percent actively using it weekly. And I mean, think about other huge technology.

 Homes, the internet.

 Yeah, smartphones, social media, whatever. None of them hit that kind of global scale across rich countries, poor countries, different cultures. None of them did it in under three years. It's completely unprecedented.

 So that speed, that fact alone tells you this isn't just another app.

 No, it's a fundamental shift. It happened almost overnight. Bypassed the usual slow crawl of adoption we see with big tech.

 Why so fast, do you think? What does the paper suggest?

 Well, it seems like the simplicity is key, right? You don't need fancy hardware. You don't need to learn code or anything.

 You just type in your own language.

 Exactly. You ask a question, you get an answer. That removes almost all the usual friction. Anybody can use it basically instantly. And that utility that just powered this crazy scaling.

 Okay, so that's our mission for this deep dive. Then we need to unpack what this study tells us. Who are these seven hundred million people?

 Right. What are they actually doing with it? Work. Play something else.

 And what do these patterns mean for, you know, how we make decisions, how we get things done. Let's get into it. Okay, so starting with that big picture, seven hundred million weekly users by mid twenty twenty five, one in ten adults globally. It's not just a tool anymore. It's it's like electricity or something, a utility.

 Yeah, it really feels that way. And the research looked really closely at where this is happening, because usually cutting edge tech starts in Silicon Valley or rich Western countries and stays there for a while.

 Yeah, right. The usual pattern.

 But not this time. The data shows ChatGPT growth is genuinely global. And here's the really interesting bit. As twenty twenty five went on, the adoption rate actually picked up speed fastest in low and middle income countries.

 Wow. Okay. That flips the script a bit, doesn't it? It's not just a toy for the wealthy.

 Not at all. It suggests something really powerful is happening there. Maybe about access to information.

 Yeah. What do you think that means? If you're somewhere with maybe limited access to, say, good libraries or expert advice or even reliable internet search, sometimes.

 Well, think about it. Suddenly you've got this. This thing that can give you pretty sophisticated information instantly. Stuff like legal advice or help understanding a health issue or even complex technical instructions.

 Stuff that might normally cost a lot or just be unavailable.

 Exactly. All you need is to be able to ask in your own language. It potentially acts as this massive democratizer like leveling the playing field for knowledge access for billions of people.

 This is a really powerful idea. Okay, so global reach, fastest growth now in developing economies. Let's zoom in on the users themselves. Who are they? Starting with age.

 Okay. Age. The numbers are pretty stark here. Nearly half, forty nine percent of all the messages they analyzed came from users under twenty six years old.

 Gen Z, basically. And the younger millennials.

 Yep. The digital natives, they grew up talking to screens, asking Siri for stuff. So chatting with an AI. No big deal for them.

 He's probably their first stop for everything, right from like, figuring out what to wear to understanding quantum physics.

 Pretty much. They seem totally comfortable integrating it into every little corner of their lives, way faster than older generations. Drafting social media posts one minute, asking for homework help the next.

 But it's not just them, right? Because that leaves the other half fifty one percent. That's a lot of messages from older groups too.

 Absolutely critical point. Definitely not just a kid thing. And the stuff older users are asking, it's often pretty complex, high stakes, personal stuff.

 Like what? Give us some examples.

 Well, the paper mentions things like older users getting help crafting arguments for rent negotiations or planning really detailed multi-country travel itineraries. Think optimizing flights, visas, budgets, serious planning.

 Okay, so maybe the younger crowd uses it more frequently for lots of little things, right?

 High volume.

 But the older users might be leveraging it for tasks that require more, I don't know, cognitive heavy lifting, things with real consequences.

 That seems to be the pattern. The twenty year old asks about celebrity gossip. The forty five year old asks for help structuring a business proposal. The sixty five year old maps out retirement finances. The utility cuts right across all ages and types of needs.

 Fascinating. Now what about gender? Because tech adoption, especially early on, usually has a pretty noticeable gender gap. Right? Skews male.

 Almost always. Yeah. Especially for, you know, things that feel technical or involve new hardware. And yeah, the data shows ChatGPT started out that way too. Back in late twenty twenty two, early twenty twenty three more men jumping on board first.

 Okay typical pattern but.

 But and this is a huge but by mid twenty twenty five the study found that gender gap basically vanished. Like poof, gone, vanished completely. Pretty much neck and neck. Yeah. And in some ways they measured it. Usage was even tipping slightly towards female users.

 Wow. That fast? In less than three years it went from male skewed to totally balanced or even slightly female skewed. That's that's really unusual for tech adoption, isn't it?

 It's incredibly fast. Think about PCs or gaming or even early internet use. Those gaps took years, sometimes decades, to close if they ever fully did.

 So why was this different? What made AI chatbots break that pattern so quickly?

 Well, the thinking is it comes down to the nature of the tool itself. It's not about hardware specs or coding or tinkering.

 It's about language.

 Exactly. It's about communication. And when you look at what people do with it, which we'll get into more detail on soon, it's stuff like writing help, getting advice, finding information.

 Tasks everyone needs to do regardless of gender.

 Precisely drafting emails, planning trips, understanding complex topics. These are universal needs of modern life, so the tools core value just immediately resonated across the board. It's an amplifier for thinking and communicating, and those aren't gendered skills.

 So the fact that the user base balanced out so quickly is maybe the strongest proof that this isn't some niche tech thing, right?

 It confirms it's a fundamental, general purpose tool for, well, for being human in the digital age.

 Okay, let's shift gears now to how these seven hundred million people are actually spending their time with ChatGPT because this next finding, honestly, it can't surprise me. It pushes back against that narrative. We always hear about AI taking over jobs.

 Are the work versus personal split. Yeah, yeah, this is a big one in the paper.

 Huge. The headline is personal. Non-work usage now massively outweighs work related usage like by a lot.

 It's a really dramatic shift they tracked. So rewind to mid twenty twenty four. Back then it was pretty close to an even split. About fifty three percent of messages were non-work. Forty seven percent work. Still slightly more personal but close.

 Okay. Pretty balanced a year or so ago.

 But then fast forward to mid twenty twenty five. Just a few months back, that non-work number, it jumped to over seventy percent seventy percent.

 So less than thirty percent of interactions are now work related.

 That's what the data shows. Personal use isn't just leading. It's growing way, way faster than work.

 Yes. That's huge. It suggests that whole early hype about this being primarily a tool to boost corporate productivity. Maybe that was a bit off.

 Well, it was part of the story, definitely, but maybe not the main story for the average user. It points towards what some people call the productivity paradox. We talk endlessly about AI's impact on business efficiency, right?

 Quarterly earnings automation.

 Most of the actual time people spend interacting with it is outside the office trying to, you know, figure out dinner, plate a vacation, or understand their kids homework. It's become more of a life assistant.

 An all purpose life assistant. Okay, but let's not ignore that thirty percent work use. It's still significant. Who are those people using it professionally? What kind of jobs?

 Yeah, the paper paints a really clear picture here. The work users are heavily concentrated among well-educated, highly paid professionals.

 Like who specifically.

 Think engineers, managers, analysts, consultants, people in marketing, sales, basically jobs that involve processing and communicating a lot of complex information knowledge workers.

 Interesting. So it's not necessarily the jobs we might have first expected, like maybe routine data entry or admin tasks.

 Not primarily, no. It seems the current strength of these models is more in augmenting complex work rather than fully replacing simpler, repetitive tasks. It's less about filling out forms automatically and more about more about helping that manager make sense of a huge pile of reports before a board meeting, or helping that analyst quickly grasp the key points of a dense financial document. It saves cognitive load on complex tasks.

 So the focus for work is really on obtaining, documenting, or interpreting information. That's nearly sixty percent of work messages, right?

 Yeah, fifty eight percent. And the rest is mostly about making decisions, solving problems or thinking creatively things that require synthesizing information.

 Okay, so that AI as an intern idea needs refining. It's not a junior intern fetching coffee.

 Definitely not. It's more like a highly skilled, incredibly fast research assistant or cowriter.

 Right. It does the first draft. It pulls out the key data points. It summarizes the background reading.

 Exactly. Think about a consultant. The AI might draft the first few versions of a client report summary or for a coder, it might explain a complex library or suggest different approaches. For a manager, it might draft a list of pros and cons for a strategic decision.

 It saves time for the most expensive employees, the knowledge workers, by handling the informational grunt work.

 That seems to be where the biggest economic value is currently being captured in the workplace, augmenting high skilled labor.

 Okay, fascinating. Now let's swing back to that massive seventy percent personal use. What's driving that growth? What kind of personal tasks are people throwing at it?

 Oh, it's incredibly broad. Almost anything you can think of relating to managing daily life, like cooking advice is huge. Asking for recipes, substitutions, techniques, personalized fitness plans, getting help, understanding complex topics, maybe for hobbies or just curiosity. Helping kids with homework.

 So it's like the ultimate search engine plus advice columnist plus tutor.

 Kind of people use it for travel planning, getting gift ideas, drafting emails to landlords or customer service, settling arguments about trivia, even seeking relationship advice or just brainstorming ideas for creative projects.

 It sounds like it's taking over a lot of the little bits of mental friction in everyday life.

 That's a great way to put it. Mental friction reduction. If you need to figure something out, instead of opening ten browser tabs and trying to piece it together.

 You just ask and ideally get one coherent answer back.

 Right? Even if it's not always perfect, that immediate synthesized response is clearly something people value enormously.

 So the big takeaway here is that it really shifted from being seen as maybe a niche tool for writers or coders.

 To being this all purpose digital helper for pretty much everyone. It's like that super knowledgeable, always available friend. You can ask anything anytime.

 Okay, so we know it's huge, we know it's global and we know personal use dominates. But what specifically are people actually asking it to do most often? The researchers managed to boil down the vast majority of interactions into just a few key categories.

 Yeah, they found a really strong pattern. Almost eighty percent of all the conversations fell into just three main buckets.

 Eighty percent. That's a massive concentration. It really tells you what people see as its core function.

 Absolutely. It shows people are primarily using it as a practical utility tool.

 Okay. So what's bucket number one?

 Number one is practical guidance. This is all the how to stuff asking for advice instructions step by step plans.

 Like the classic how do I fix a leaky faucet example.

 That's the simple version. Yeah. But it goes much deeper. People are asking things like, give me a detailed plan to build a vegetable garden in a small urban balcony, or explain the pros and cons of different mortgage refinancing options right now, or even outline the steps to start a small online business.

 So it's about getting actionable information that helps you do something in the real world.

 Exactly. Actionable output, not just links to websites, but an actual synthesized plan or explanation you can use immediately. That's a key difference from just googling it, right?

 Cuts down the research time dramatically. Okay, that's practical guidance. What's number two?

 Number two seeking information. This is closer to using it like an enhanced search engine or encyclopedia.

 So asking factual questions.

 Yeah. Things like explain quantum computing in simple terms. Or what were the main causes of the fall of the Roman Empire, or summarize the plot of this book.

 People aren't looking for a list of links here either, are they? They want the answer.

 Synthesize precisely. They want a single cohesive explanation, a narrative that makes sense right away. It suggests people often prefer that immediate comprehension, even if they know they might need to double check the details later over wading through pages of search results.

 Trading absolute certainty for speed and coherence. Makes sense. Okay. And the third big category.

 This one's the real powerhouse. Especially in that thirty percent work usage we talked about. Writing assistants.

 Are okay. This covers everything text related.

 Everything drafting emails, letters, reports, editing and proofreading existing text, translating languages, summarizing long documents, generating creative writing like poems or stories, helping with essays or presentations.

 This must be where a huge chunk of that professional use comes in.

 Definitely in the knowledge economy, communication is king and the AI is acting like a massive accelerator for producing and refining text. Think about drafting a tricky diplomatic email, or summarizing a one hundred page technical report, or translating marketing copy for different regions.

 At the time. Savings must be enormous.

 Huge. It just underscores why those knowledge workers are the primary professional users. The AI directly boosts their core output. Written communication.

 Okay, so those three practical guidance, seeking information and writing assistance account for nearly eighty percent of everything people do with ChatGPT. It's a language and utility engine.

 That's the core story.

 Which brings us to the big surprise, the outlier, the thing that doesn't fit that pattern as much as you might expect, right?

 The coding surprise.

 Yeah. We hear constantly about AI writing code, revolutionizing software development, AI pair programmers all the hype, but the study found that actual coding assistance makes up. Oh, was it a tiny fraction?

 Tiny. Only about four point two percent of all the messages analyzed were related to coding.

 Four percent. That seems really low given the buzz. Does it mean the AI isn't actually very good at coding?

 Not necessarily. It might be brilliant at coding, but it means the number of people asking it for coding help is just dwarfed by the sheer volume of people asking for everything else.

 Ah, okay. It's a denominator issue.

 Exactly. Think about those seven hundred million weekly users. How many of them are professional software developers versus, say, students needing homework help? Parents planning meals managers writing reports or retirees figuring out travel.

 The number of people who need help writing an email or finding a recipe is just orders of magnitude larger than the number who need help debugging Python code precisely.

 So while coding is a complex high value task, the AI can do. It's just not the main thing most people need help with in their daily lives.

 So this finding actually reinforces the main point, doesn't it?

 Absolutely. It highlights that the AI revolution, at least for the masses right now, is primarily about augmenting universal human skills, communication, information access, practical problem solving much more than it is about automating niche technical skills like programming language is the killer app here.

 Let's dig a bit deeper now into how people phrase their requests. The way they talk to the AI tells us something about their intent, right? The researchers broke this down.

 Yeah. They looked at whether users were primarily asking questions, giving instructions, or just chatting. It reveals whether they see the AI as an information source or a task doer.

 Okay, so what's the biggest category there?

 The largest chunk. Almost half at forty nine percent, was classified as asking people, basically treating it like a giant Q&A machine. What is x? Explain why. Why did Z happen?

 A great answer machine. Yeah. Seeking understanding.

 Right behind it though. At forty percent was instructing. This is where users are telling the AI to do something specific.

 Like draft this email, write that poem, create a list of these things.

 Exactly. Generate content. Perform this task. This is treating the AI more like a personal assistant or a production engine. Make this for me.

 Okay. So asking and instructing are the two big ones making up almost ninety percent combined. What's the last little slice?

 The remaining eleven percent was classified as conversing or expressing. This is the more open ended stuff. People just chatting, maybe using it for brainstorming, journaling, exploring ideas without a specific task in mind.

 The kind of interaction that maybe gets a lot of headlines, but isn't the main way people use it day to day.

 Seems that way. Yeah. The practical stuff dominates now.

 Does this balance shift when people are using it for work?

 Ah good question. Yes it does. Significantly, when people are on the clock that instructing category jumps up.

 They're telling it what to do more often.

 Yep. For work related messages fifty six percent were instructions. Draft this report. Summarize this meeting. Analyze this data.

 Okay, that makes sense. At work you need output. You need deliverables. Time is money.

 Exactly. It confirms that in a professional setting, the EHS primary role is seen as a productivity engine to generate tangible work products, not just answer background questions. Get the job done.

 Which leads us nicely into the study's big economic conclusion, right? Based on all these patterns, how people use it, what they ask, how they ask, what's its main economic value?

 The authors argue really strongly that Chatgpt's biggest economic impact comes from its role as a decision support and productivity tool.

 Okay, unpack that phrase. Decision support. How is that different from just being a better search engine? Because search gives you information too.

 It's a crucial difference. Think about traditional search. You type in a query, you get back a list of links, maybe some snippets, raw ingredients.

 Right? Then you have to click through, read everything, figure out what's relevant, compare different sources.

 Synthesize it all in your head, weigh the pros and cons, and then maybe draft an email or make a decision that takes a lot of time and brainpower.

 Okay, so search gives you the raw data. What does ChatGPT do differently for decision support?

 It does a lot of that synthesis for you. You can ask it not just for the raw data, but for the actionable output directly.

 So instead of searching risks of market entry strategy X and reading ten articles.

 You can ask based on these articles or even just general knowledge, summarize the top five risks of market entry strategy X ranked by potential, impact, and list possible mitigation steps for each.

 Ah, okay. It delivers the analysis, the structured output, not just the source material.

 Exactly. It provides tailored, actionable output. The drafted email, the pros cons list the summarized risks saving immense amounts of time and cognitive load, especially on complex information processing tasks.

 And the study sees this happening across lots of different professional fields.

 Yeah, especially in those knowledge intensive areas. We mentioned management, engineering consulting, sales analytics. Anywhere that's synthesizing information is a bottleneck. That ability to handle the heavy lifting of information processing to directly support human decision making, that's where the real economic leverage seems to be.

 It's like offloading the mental grunt work.

 That's a perfect way to put it. Cognitive offloading. It frees up the human expert to focus on the parts the AI can't do yet. The final judgment call the strategic insight. Handling ambiguity, building relationships, the ethical considerations, the truly human parts of the job.

 Okay, so we've covered the scale the who, the what, the how. The last big piece is. Does it actually work? Are people happy with the results they're getting from these interactions?

 Right? The ultimate report card and the news here is generally very positive for the AI.

 What did the numbers show?

 They found that positive interactions significantly outnumber negative ones by about four to one four to one positive.

 So roughly an eighty percent satisfaction rate overall.

 That's the ballpark. Yeah. Which when you think about the sheer complexity of what people are asking it to do, write essays, explain physics, debug code, plan vacations. Achieving eighty percent satisfaction is pretty remarkable.

 It really is. No wonder it spreads so fast. If it only worked, say half the time, people would have given up pretty quickly.

 Exactly. That high success rate is clearly what cemented it as a useful tool, and drove that massive adoption and habit formation. People keep coming back because most of the time it actually helps them.

 But there's always a but with data, isn't there was satisfaction equal across all types of interactions.

 Uh, no. And this is a really interesting nuance. They found that asking interactions, just seeking information were rated more positively than doing or instructing interactions where the AI had to generate something specific.

 Hmm. So people are happier when they ask what is photosynthesis than when they ask, right? A marketing slogan for my new organic dog food?

 Generally, yes. That seems to be the trend. Asking for factual summaries or explanations usually leads to pretty coherent, verifiable answers. The AI is good at retrieval and synthesis, so high satisfaction.

 Okay. Makes sense. And why lower satisfaction for the doing tasks?

 Well, when you ask it to create something new an essay, a poem, a business plan code, the output is much more subjective, right?

 It might be grammatically perfect, factually accurate based on the prompt.

 But it might not capture the exact tone you wanted, or the specific creative angle or the nuance you had in your head. It might just feel a bit off Or generic.

 So there's more room for a meh reaction, even if the AI technically did what you asked.

 Exactly. It suggests that while these llms are amazing collaborators for gathering and structuring information, that final layer of subjective judgment, creativity, and personal style often still needs significant human guidance or refinement to be truly satisfying.

 Okay, so incredible at summarizing. Pretty good at generating, but the human touch is still key. For that last mile of creation.

 That seems to be where we are now.

 So pulling it all together, this incredible speed of adoption, the massive user base, the generally high satisfaction. What does this tell us about the future? Is interacting with AI like this just the new normal?

 All signs point that way. It really feels like interacting with information via natural language. AI is becoming a fundamental interface, maybe even the primary interface for a lot of tasks. It's not a passing fad, it's a deep behavioral shift.

 And the study really hammers home that decision support role, doesn't it? Suggesting a future where the AI handles more and more of the information processing grunt work?

 Yeah, the heavy lifting of finding, sorting, summarizing and even initial analysis, which theoretically frees up humans to focus more on those higher order skills.

 Like judgment, empathy, ethical reasoning, complex problem solving, the stuff AI struggles with.

 That's the optimistic view. Yeah, the AI handles the what humans handle the so what and the what next.

 How do you see this playing out in terms of technology integration? Will we always be going to a separate ChatGPT website or app?

 Probably not for long, given how easy it is to use just plain language. No special skills needed. The obvious next step is embedding this capability everywhere.

 Like built into your operating system, your email program, your work software.

 Exactly. It won't be a destination you visit. It'll be an ambient layer of intelligence woven into the tools you already use every day. Think spell check. But for summarizing reports, drafting emails, or answering questions contextually within whatever app you're using.

 Which would presumably push usage even higher and make it even more seamless.

 Almost certainly, it would become the silent operating system for how we interact with information and get knowledge work done. Hashtag outrage. Outro.

 All right. That was a really deep dive into this new NBER research. Let's try and boil down the absolute key takeaways for you, our listeners.

 Okay. Number one, ChatGPT adoption is historically fast and globally massive. Seven hundred million weekly users, ten percent of adults in under three years. Unprecedented.

 Number two, the user base is surprisingly balanced. Now, age wise, it's not just kids and the gender gap closed incredibly quickly. It's truly mainstream.

 Number three personal use dominates over seventy percent of interactions. Are people using it as a life assistant for practical advice, info gathering and planning far outweighing workplace use?

 Number four, that workplace use is concentrated among high skill knowledge workers, using it primarily for writing assistance and information synthesis, augmenting their productivity.

 Number five. The core functions that make up eighty percent of usage are practical guidance, seeking information, and writing assistance. Coding is surprisingly niche in comparison.

 And number six satisfaction is high around eighty percent, though people are generally happier asking it questions than instructing it to create something complex from scratch.

 So my final thought on the biggest trend here, it's crystal clear that the primary economic and social value of this technology right now lies in its power to augment human communication and decision making.

 It's a language amplifier, a cognitive offload for.

 Exactly less about replacing niche technical skills like coding, and much more about boosting the universal skills of processing information and expressing ideas for everyone.

 So the takeaway for you listening is that people, millions of them, are already finding really practical, constructive ways to use AI. It's not just hype. It's becoming a utility to be more informed, maybe more efficient, possibly even more creative in daily life.

 But we have to end with that provocative thought, right? The paper points to this eighty percent satisfaction rate and the AI's power in decision support.

 Yeah, if the AI is doing eighty percent of the analysis handling the information overload, what happens to our own judgment?

 Does that amazing convenience, that eighty percent success rate eventually lead to a kind of cognitive complacency? Do we start trusting the output too much? Stop doing the hard critical thinking ourselves.

 Or does that remaining twenty percent? The errors, the weird outputs, the times? It's just does that act as a permanent check, a necessary friction that forces us to stay engaged, to keep questioning, to remain the ultimate arbiters of truth and the final decision makers.

 That's the billion dollar question, isn't it? Efficiency versus critical thinking in the age of AI. Something for you to definitely mull over.

 Indeed, where does that balance lie? We'll have to see. Thank you for joining us for this deep dive.

 Catch you next time.